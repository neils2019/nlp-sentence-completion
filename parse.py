#!/usr/bin/python

import nltk
import argparse
import os
import re
import json

########
#  Neil Joshi - nnjoshi@gmail.com
#


###########################################
#
# Create model training file, text file from json provided training set file, 
# 'sample_conversations.json'.
#
# Text file consists of messages from 'sample_conversations' generated by 
# customer service operator, therefor json field for each message 
# 'IsFromCustomer == FALSE.
#
# Text File consists of messages from customer service operator from test 
# set file : 'sample_conversations.json'
#
#  JSON provided training set file to training set file for model:
#  Issues:Messages{text,IsFromCustomer} => for each issues, for each message
#                                           select text from message where
#                                           IsFromCustomer == FALSE
#
#
def isValid(elem):
    res = False
    CUSTOMER_KEY = 'IsFromCustomer'
    if elem[CUSTOMER_KEY] == True:
        return res
    else:
        return True

def getText(elem):
    s = ""
    TEXT_KEY = 'Text'
    if isValid(elem) == True:
        s = elem[TEXT_KEY]
    return s



def readJson(fileName):
    obj = json.loads(file(fileName,"r").read())
    return obj

############
#
# function: preprocessStr
#
# description: filter message string, tokenize into words, keeping all 
#              alphanumeric characters and abbrev.
#             
#              returns string of sentences separated by 
#              new line '\n' from original message
def preprocessStr(s):
    if s != "":
        fs = ""
        vals = re.findall("[A-Za-z0-9\;\'\-\s]+",s)
        try:
            #print vals
            for e in vals:
                if e != '':
                    fs = fs + e.lower().strip(" ")+"\n"
        except:
            pass
        if fs != "":
            s = fs
    #else:
    #s = s+"\n"
    return s



############
#
# function: createDataSet
#
# description: Main function.  Given JSON python object for 
#              'sample_conversations', return string of sentences delimited by
#              new line '\n' for messages originated by customer service 
#              operator.
def createDataSet(obj):
    ds = ""
    ISSUES = 'Issues'
    MESSAGES = 'Messages'
    l = obj[ISSUES]
    

    for e in l:
        for m in e[MESSAGES]:
            ds = ds + preprocessStr(getText(m))
            #ds = ds + " "+getText(m)
    
    return (ds)

if __name__=='__main__':
    cmdline = argparse.ArgumentParser(description='Model training file Generator')
    cmdline.add_argument('json_infile', type=str, help='Sample Conversation Json file name and path, eg. ./sample_conversations.json')
    cmdline.add_argument('osent_file', type=str, help='name and path of output sentence training file, eg. ./utt.txt')
    args = cmdline.parse_args()

    js=readJson(args.json_infile)
    ofile = file(args.osent_file,"w")
    ofile.write(createDataSet(js))
    
    ofile.close()
    ifile = file(args.osent_file,"r")
    for line in ifile:
        for sentence in nltk.sent_tokenize(line):
            print(' '.join(nltk.word_tokenize(sentence)).lower())

    ifile.close()

    
